DATA:
  dataset: unc
  data_root: ./ln_data
  split_root: ./ln_data
  train_split: train
  val_split: val

TRAIN:
  visual_adapter_dim: 56 
  visual_adapter_layer: [18, 19, 20, 21, 22, 23]
  txt_adapter_dim: 56
  txtual_adapter_layer: [1,3,5,7,9,11]
  # Base Arch
  clip_pretrain: ./pretrain/ViT-B-16.pt
  dino_pretrain: ./pretrain/dinov2_vitl14_reg4_pretrain.pth
  dino_name: dinov2-large
  dino_layers: 24
  output_dinov2: [8, 16]
  model_name: CLIP-b-16
  input_size: 224 
  word_len: 40 
  word_dim: 512
  ladder_dim: 64
  nhead: 8
  vis_dim: 512

  sync_bn: True
  dinov2: True #双encoder
  dinov2_only_backbone: True #dino替代clip
  # Decoder
  num_layers: 3
  num_head: 8
  dim_ffn: 512
  dropout: 0.1
  intermediate: False #decoder部分的修改
  # Training Setting
  workers: 32  # data loader workers
  workers_val: 16
  epochs: 90 
  milestones: [60]
  start_epoch: 0
  batch_size: 32  # batch size for training
  batch_size_val: 32  # batch size for validation during training, memory and speed tradeoff
  base_lr: 0.0001
  lr_decay: 0.1
  lr_multi: 1
  weight_decay: 0.
  max_norm: 0.
  manual_seed: 0
  print_freq: 100
  # Resume & Save
  exp_name: L_V14
  output_folder: exp/refcoco
  save_freq: 1
  weight:  # path to initial weight (default: none)
  resume:  # path to latest checkpoint (default: none)
  evaluate: True  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend
Distributed:
  dist_url: tcp://localhost:3682
  dist_backend: 'nccl'
  multiprocessing_distributed: True
  world_size: 1
  rank: 0
TEST:
  test_split: val-test
  visualize: True  
